#! /usr/bin/env python
import pickle
import os
import sys
import time
import logging
import argparse
from terra_common import CoordinateConverter as CC
from find_crop_position import find_crop_position
from multiprocessing import Pool
from datetime import datetime


def parse_args():
    # TODO add arg for globus refresh token
    description = 'usage '
    parser = argparse.ArgumentParser(description=description)
    parser.add_argument('--raw-path', help='path to the root of raw data', required=True)
    parser.add_argument('--ply-path', help='path to the root of ply data', required=True)
    parser.add_argument('--start', help='Start date. Format: yyyy-mm-dd', required=True)
    parser.add_argument('--end', help='End date. Format: yyyy-mm-dd', required=True)
    parser.add_argument('-p', '--processes', help='number of sub-processes', default=4, type=int)
    args = parser.parse_args()
    return args

# TODO load a cc and dump to some where
cc = CC(useSubplot=True)
cc.bety_query('2017-05-12', useSubplot=True)
with open('./coord_convert.pkl', 'wb') as f:
    pickle.dump(cc, f)

args = parse_args()
logger = logging.getLogger('scan_crop_ppln_main')
logger.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(name)s %(levelname)s: \t%(message)s')
ch = logging.StreamHandler()
ch.setLevel(logging.INFO)
ch.setFormatter(formatter)
logger.addHandler(ch)
logger.info('\n\t raw data path: {}'
            '\n\t ply data path: {} '
            '\n\t start date: {}'
            '\n\t end date: {}'
            '\n\t number of processes: {}'
            .format(args.raw_path, args.ply_path, args.start, args.end, args.processes))

start_date = datetime.strptime(args.start, '%Y-%m-%d')
end_date = datetime.strptime(args.end, '%Y-%m-%d')

# TODO check folder existence
logger.info('scanning folders')
task_list = []
for date_folder in os.listdir(args.raw_path):
    folder_date = datetime.strptime(date_folder, '%Y-%m-%d')
    if folder_date < start_date or folder_date > end_date:
        continue
    raw_date_folder_path = os.path.join(args.raw_path, date_folder)
    ply_date_folder_path = os.path.join(args.ply_path, date_folder)
    for sub_folder in os.listdir(raw_date_folder_path):
        # task format: raw_data_folder, ply_data_folder, output_folder,
        #              sensor_name='east', download_ply=False, per_plot=True, log_lv=logging.DEBUG):
        task_raw_path = os.path.join(raw_date_folder_path, sub_folder)
        task_ply_path = os.path.join(ply_date_folder_path, sub_folder)
        task = (task_raw_path, task_ply_path)
        task_list.append(task)
total_tasks = len(task_list)
logger.info('total task: {}'.format(total_tasks))
pool = Pool(processes=args.processes)
count = 0
rs = pool.starmap_async(find_crop_position, task_list)
while True:
    if rs.ready():
        break
    remaining = rs._number_left
    logger.info('remain/total: {}/{}'.format(remaining, total_tasks))
    time.sleep(60 * 5)
